{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"accelerator":"TPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"ec5849d8a5434e368153925d3c926271":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e52a776978447cfb9bdd2dd4b55eca8","IPY_MODEL_119499edff2041d9a7800523a433ad7e","IPY_MODEL_e2b569d279ad4a77997edef9b048ad23"],"layout":"IPY_MODEL_3a4fcbff6ae14ebe82ff5f9afa51eea5"}},"4e52a776978447cfb9bdd2dd4b55eca8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f76da56542de46a6825c8efea1ecdce6","placeholder":"​","style":"IPY_MODEL_97281a8776a64c798113552e532fd901","value":"Downloading: 100%"}},"119499edff2041d9a7800523a433ad7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_80c965eb8a40402c8f8a5af8eac653e0","max":791656,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cac07e15804d4e13bb6f9c515e50253a","value":791656}},"e2b569d279ad4a77997edef9b048ad23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f32c4f17126a4f8e9ee5c9603eb108f5","placeholder":"​","style":"IPY_MODEL_a9220a0ea4484ad6977243b1eb33a739","value":" 792k/792k [00:00&lt;00:00, 1.15MB/s]"}},"3a4fcbff6ae14ebe82ff5f9afa51eea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f76da56542de46a6825c8efea1ecdce6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97281a8776a64c798113552e532fd901":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"80c965eb8a40402c8f8a5af8eac653e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cac07e15804d4e13bb6f9c515e50253a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f32c4f17126a4f8e9ee5c9603eb108f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9220a0ea4484ad6977243b1eb33a739":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7403bbee5c0841669ebac6cceeae6bd4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c6b4377d2e8a478f82e2b1eefa49716b","IPY_MODEL_88ab93f1ed214b99b96cf1296ffa2d29","IPY_MODEL_3ebe4aeeffed4036943118a47e35c217"],"layout":"IPY_MODEL_39b5a8ce920641718ad234284f70f7d9"}},"c6b4377d2e8a478f82e2b1eefa49716b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_879f46c408f14659a50d251aad6f68ee","placeholder":"​","style":"IPY_MODEL_8d0d63a621504a41bd6e98dc666560c1","value":"Downloading: 100%"}},"88ab93f1ed214b99b96cf1296ffa2d29":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1255f4ec9fa6462ea9f11700a76dc4a2","max":1199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_42fc0f7c5baf478396d1d7049859b474","value":1199}},"3ebe4aeeffed4036943118a47e35c217":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b895836485d4671a798ad7ef1fd5abd","placeholder":"​","style":"IPY_MODEL_ba96a54429f94eb5b6becd5e46a619c4","value":" 1.20k/1.20k [00:00&lt;00:00, 6.95kB/s]"}},"39b5a8ce920641718ad234284f70f7d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"879f46c408f14659a50d251aad6f68ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d0d63a621504a41bd6e98dc666560c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1255f4ec9fa6462ea9f11700a76dc4a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42fc0f7c5baf478396d1d7049859b474":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0b895836485d4671a798ad7ef1fd5abd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba96a54429f94eb5b6becd5e46a619c4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5453f3f9a5af4c91b247567c9d4369b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_892f4760839a4b86a49a30c9bad8cb80","IPY_MODEL_ffbbabfbb324415db8912f4b9c2375f3","IPY_MODEL_fd72af1849d046cf98a26adf3a958882"],"layout":"IPY_MODEL_aed58cac1cf9462fb8dafa4ed79ced37"}},"892f4760839a4b86a49a30c9bad8cb80":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e7b3a9953d0480d9235db06aca8528c","placeholder":"​","style":"IPY_MODEL_0d50c1c93cff48bfb2a792c0fe3b6221","value":"Downloading: 100%"}},"ffbbabfbb324415db8912f4b9c2375f3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0accde61d1944696a0acaabf87bd3484","max":891691430,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e34482676cd74cc7a302729c463803d9","value":891691430}},"fd72af1849d046cf98a26adf3a958882":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_542c536a1b9a437796d24ac4e52d4baf","placeholder":"​","style":"IPY_MODEL_8a900107689043a9af4244a7d4a15a6d","value":" 892M/892M [00:39&lt;00:00, 29.8MB/s]"}},"aed58cac1cf9462fb8dafa4ed79ced37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e7b3a9953d0480d9235db06aca8528c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d50c1c93cff48bfb2a792c0fe3b6221":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0accde61d1944696a0acaabf87bd3484":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e34482676cd74cc7a302729c463803d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"542c536a1b9a437796d24ac4e52d4baf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a900107689043a9af4244a7d4a15a6d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/","metadata":{"id":"qeL5hXX1Bz_t"}},{"cell_type":"code","source":"!pip install sentencepiece\n!pip install transformers\n!pip install rich[jupyter]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bbwl6E1E205R","outputId":"ae22dd8b-1b78-4b76-92f6-ab60ce5b9582","execution":{"iopub.status.busy":"2022-11-29T16:17:30.085479Z","iopub.execute_input":"2022-11-29T16:17:30.085754Z","iopub.status.idle":"2022-11-29T16:18:01.220053Z","shell.execute_reply.started":"2022-11-29T16:17:30.085725Z","shell.execute_reply":"2022-11-29T16:18:01.219207Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (0.1.96)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.5.1)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.45)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.62.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers) (21.0)\nRequirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.3)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (3.4.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.8.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.25.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.5.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.7.4.3)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers) (2.4.7)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (4.0.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.6)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.1)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.0.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.15.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\nCollecting rich[jupyter]\n  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n\u001b[K     |████████████████████████████████| 237 kB 264 kB/s eta 0:00:01\n\u001b[?25hCollecting typing-extensions<5.0,>=4.0.0\n  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\nRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /opt/conda/lib/python3.7/site-packages (from rich[jupyter]) (2.10.0)\nCollecting commonmark<0.10.0,>=0.9.0\n  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n\u001b[K     |████████████████████████████████| 51 kB 2.1 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: ipywidgets<8.0.0,>=7.5.1 in /opt/conda/lib/python3.7/site-packages (from rich[jupyter]) (7.6.3)\nRequirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.5.1)\nRequirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (6.2.0)\nRequirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.1.3)\nRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (7.26.0)\nRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.0.5)\nRequirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.0.0)\nRequirement already satisfied: importlib-metadata<5 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.4.0)\nRequirement already satisfied: tornado<7.0,>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (6.1)\nRequirement already satisfied: debugpy<2.0,>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.4.1)\nRequirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.1.2)\nRequirement already satisfied: argcomplete>=1.12.3 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.12.3)\nRequirement already satisfied: jupyter-client<8.0 in /opt/conda/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (6.1.12)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.5.0)\nRequirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (5.0.9)\nRequirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.2.0)\nRequirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (57.4.0)\nRequirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.18.0)\nRequirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.0.19)\nRequirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.8.0)\nRequirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.8.2)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.8.0)\nRequirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.7.1)\nRequirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (22.2.1)\nRequirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.2.0)\nRequirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.2.0)\nRequirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (21.2.0)\nRequirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.17.3)\nRequirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.15.0)\nRequirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.7.0)\nRequirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.2.5)\nRequirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.7/site-packages (from widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (6.4.3)\nRequirement already satisfied: prometheus-client in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.11.0)\nRequirement already satisfied: nbconvert in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (6.1.0)\nRequirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.8.0)\nRequirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.10.1)\nRequirement already satisfied: argon2-cffi in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (20.1.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (3.0.1)\nRequirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.14.6)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.20)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.0.1)\nRequirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.8.4)\nRequirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.7.1)\nRequirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.3)\nRequirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.5.4)\nRequirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.1.2)\nRequirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.5.0)\nRequirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.4.2)\nRequirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (4.0.0)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.7/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (1.5.1)\nRequirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (0.5.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (21.0)\nRequirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets<8.0.0,>=7.5.1->rich[jupyter]) (2.4.7)\nInstalling collected packages: typing-extensions, commonmark, rich\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing-extensions 3.7.4.3\n    Uninstalling typing-extensions-3.7.4.3:\n      Successfully uninstalled typing-extensions-3.7.4.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 21.8.3 requires cupy-cuda110, which is not installed.\ntensorflow 2.4.1 requires typing-extensions~=3.7.4, but you have typing-extensions 4.4.0 which is incompatible.\narviz 0.11.2 requires typing-extensions<4,>=3.7.4.3, but you have typing-extensions 4.4.0 which is incompatible.\naiobotocore 1.4.1 requires botocore<1.20.107,>=1.20.106, but you have botocore 1.21.44 which is incompatible.\u001b[0m\nSuccessfully installed commonmark-0.9.1 rich-12.6.0 typing-extensions-4.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"'''from google.colab import drive\ndrive.mount('/content/drive')'''","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KuvCIQ-hYPQ2","outputId":"ffdc0085-ccd2-4d26-c84c-8c1bfc7561ce","execution":{"iopub.status.busy":"2022-11-29T16:18:01.223476Z","iopub.execute_input":"2022-11-29T16:18:01.223713Z","iopub.status.idle":"2022-11-29T16:18:01.231152Z","shell.execute_reply.started":"2022-11-29T16:18:01.223684Z","shell.execute_reply":"2022-11-29T16:18:01.230470Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"\"from google.colab import drive\\ndrive.mount('/content/drive')\""},"metadata":{}}]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/parallel/parallel_detoxification_dataset_small.tsv', sep='\\t')\n#df = pd.read_csv(\"https://github.com/s-nlp/parallel_detoxification_dataset/blob/main/parallel_detoxification_dataset_small.tsv\", error_bad_lines=False)\n#df = pd.read_csv('/content/drive/MyDrive/Project-5800/parallel.csv', error_bad_lines=False)\ndf.head()","metadata":{"id":"y6nEben93JAk","colab":{"base_uri":"https://localhost:8080/","height":228},"outputId":"835f6c21-de6e-4407-e51e-92d13a8fbe40","execution":{"iopub.status.busy":"2022-11-29T16:18:01.233360Z","iopub.execute_input":"2022-11-29T16:18:01.233779Z","iopub.status.idle":"2022-11-29T16:18:01.288305Z","shell.execute_reply.started":"2022-11-29T16:18:01.233745Z","shell.execute_reply":"2022-11-29T16:18:01.287454Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                       toxic_comment  \\\n0  . or the loud ass one - thousand ton beast roa...   \n1  \" mandated \" and \" right fucking now \" would b...   \n2  \" mandated \" and \" right fucking now \" would b...   \n3  \" mandated \" and \" right fucking now \" would b...   \n4  * neither * of my coworkers gave a shit when i...   \n\n                                       civil_comment  \n0  or the loud  one - thousand ton beast roaring ...  \n1          \"Mandated' and \"right now\" would be good.  \n2          \"mandated\" and\" right away\" would be good  \n3                   mandated and right would be good  \n4  Neither of my co-workers cared when it came to...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_comment</th>\n      <th>civil_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>. or the loud ass one - thousand ton beast roa...</td>\n      <td>or the loud  one - thousand ton beast roaring ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>\" mandated \" and \" right fucking now \" would b...</td>\n      <td>\"Mandated' and \"right now\" would be good.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\" mandated \" and \" right fucking now \" would b...</td>\n      <td>\"mandated\" and\" right away\" would be good</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\" mandated \" and \" right fucking now \" would b...</td>\n      <td>mandated and right would be good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>* neither * of my coworkers gave a shit when i...</td>\n      <td>Neither of my co-workers cared when it came to...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.sample(10)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":386},"id":"Suxgy7wC4IqL","outputId":"259c138f-8c6f-4f3a-80ab-7589f5044425","execution":{"iopub.status.busy":"2022-11-29T16:18:01.290227Z","iopub.execute_input":"2022-11-29T16:18:01.290538Z","iopub.status.idle":"2022-11-29T16:18:01.301196Z","shell.execute_reply.started":"2022-11-29T16:18:01.290507Z","shell.execute_reply":"2022-11-29T16:18:01.300214Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                          toxic_comment  \\\n1128                         i will gonna destroy you .   \n444          do people actually believe this shit ? ? ?   \n2363  useful idiots ) of course , the russians are s...   \n236   at least one party gives a crap about humans a...   \n878               holy shit i thought that was a joke .   \n907   how about fuck whiny cunts who buy seats knowi...   \n2728                you missed the fucked up sentence .   \n1931                  that guy used to be a real dick .   \n16    &gt today was one of the most fucked up days o...   \n977    i couldn t even tell what the fuck it s saying .   \n\n                                          civil_comment  \n1128                            I will gonna defeat you  \n444                             Do people believe this?  \n2363  The Russians are still at it that's what they ...  \n236    at least one part cares about humans after birth  \n878                           I thought that was a joke  \n907   how about whiners who buy seats knowing others...  \n2728                            you missed the sentence  \n1931                          that guy is not good guy.  \n16                           I'm having a bad day today  \n977                       I couldn't tell what it says.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_comment</th>\n      <th>civil_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1128</th>\n      <td>i will gonna destroy you .</td>\n      <td>I will gonna defeat you</td>\n    </tr>\n    <tr>\n      <th>444</th>\n      <td>do people actually believe this shit ? ? ?</td>\n      <td>Do people believe this?</td>\n    </tr>\n    <tr>\n      <th>2363</th>\n      <td>useful idiots ) of course , the russians are s...</td>\n      <td>The Russians are still at it that's what they ...</td>\n    </tr>\n    <tr>\n      <th>236</th>\n      <td>at least one party gives a crap about humans a...</td>\n      <td>at least one part cares about humans after birth</td>\n    </tr>\n    <tr>\n      <th>878</th>\n      <td>holy shit i thought that was a joke .</td>\n      <td>I thought that was a joke</td>\n    </tr>\n    <tr>\n      <th>907</th>\n      <td>how about fuck whiny cunts who buy seats knowi...</td>\n      <td>how about whiners who buy seats knowing others...</td>\n    </tr>\n    <tr>\n      <th>2728</th>\n      <td>you missed the fucked up sentence .</td>\n      <td>you missed the sentence</td>\n    </tr>\n    <tr>\n      <th>1931</th>\n      <td>that guy used to be a real dick .</td>\n      <td>that guy is not good guy.</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>&amp;gt today was one of the most fucked up days o...</td>\n      <td>I'm having a bad day today</td>\n    </tr>\n    <tr>\n      <th>977</th>\n      <td>i couldn t even tell what the fuck it s saying .</td>\n      <td>I couldn't tell what it says.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df[\"toxic_comment\"] = \"summarize: \"+df[\"toxic_comment\"]","metadata":{"id":"AYfBicZQ59Jf","execution":{"iopub.status.busy":"2022-11-29T16:18:01.302525Z","iopub.execute_input":"2022-11-29T16:18:01.303044Z","iopub.status.idle":"2022-11-29T16:18:01.324014Z","shell.execute_reply.started":"2022-11-29T16:18:01.302928Z","shell.execute_reply":"2022-11-29T16:18:01.323177Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"id":"81f4PKa1F6aM","colab":{"base_uri":"https://localhost:8080/","height":228},"outputId":"84e75e81-cd70-467f-9ed6-6f9aab7d7644","execution":{"iopub.status.busy":"2022-11-29T16:18:01.330287Z","iopub.execute_input":"2022-11-29T16:18:01.332511Z","iopub.status.idle":"2022-11-29T16:18:01.343223Z","shell.execute_reply.started":"2022-11-29T16:18:01.332343Z","shell.execute_reply":"2022-11-29T16:18:01.342333Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                       toxic_comment  \\\n0  summarize: . or the loud ass one - thousand to...   \n1  summarize: \" mandated \" and \" right fucking no...   \n2  summarize: \" mandated \" and \" right fucking no...   \n3  summarize: \" mandated \" and \" right fucking no...   \n4  summarize: * neither * of my coworkers gave a ...   \n\n                                       civil_comment  \n0  or the loud  one - thousand ton beast roaring ...  \n1          \"Mandated' and \"right now\" would be good.  \n2          \"mandated\" and\" right away\" would be good  \n3                   mandated and right would be good  \n4  Neither of my co-workers cared when it came to...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>toxic_comment</th>\n      <th>civil_comment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>summarize: . or the loud ass one - thousand to...</td>\n      <td>or the loud  one - thousand ton beast roaring ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>summarize: \" mandated \" and \" right fucking no...</td>\n      <td>\"Mandated' and \"right now\" would be good.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>summarize: \" mandated \" and \" right fucking no...</td>\n      <td>\"mandated\" and\" right away\" would be good</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>summarize: \" mandated \" and \" right fucking no...</td>\n      <td>mandated and right would be good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>summarize: * neither * of my coworkers gave a ...</td>\n      <td>Neither of my co-workers cared when it came to...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Renaming the columns\n#df.columns = [\"input_text\",\"target_text\"]\n# Adding a prefix. Here we shall keep \"paraphrase\" as a prefix.\n#df[\"prefix\"] = \"paraphrase\"","metadata":{"id":"sdvqtkNV9442","execution":{"iopub.status.busy":"2022-11-29T16:18:01.344820Z","iopub.execute_input":"2022-11-29T16:18:01.345034Z","iopub.status.idle":"2022-11-29T16:18:01.350557Z","shell.execute_reply.started":"2022-11-29T16:18:01.345008Z","shell.execute_reply":"2022-11-29T16:18:01.350024Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"'''from sklearn.model_selection import train_test_split\ntrain_data,test_data = train_test_split(df,test_size=0.1)'''","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":57},"id":"g7FcbwBd98hL","outputId":"93af3046-ced9-405b-c75b-4c2c4b5d995f","execution":{"iopub.status.busy":"2022-11-29T16:18:01.351745Z","iopub.execute_input":"2022-11-29T16:18:01.353055Z","iopub.status.idle":"2022-11-29T16:18:01.358624Z","shell.execute_reply.started":"2022-11-29T16:18:01.353029Z","shell.execute_reply":"2022-11-29T16:18:01.358110Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'from sklearn.model_selection import train_test_split\\ntrain_data,test_data = train_test_split(df,test_size=0.1)'"},"metadata":{}}]},{"cell_type":"code","source":"# Importing libraries\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\nimport os\n\n# Importing the T5 modules from huggingface/transformers\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration\n\nfrom rich.table import Column, Table\nfrom rich import box\nfrom rich.console import Console\n\n# define a rich console logger\nconsole=Console(record=True)\n\ndef display_df(df):\n  \"\"\"display dataframe in ASCII format\"\"\"\n\n  console=Console()\n  table = Table(Column(\"toxic_comment\", justify=\"center\" ), Column(\"civil_comment\", justify=\"center\"), title=\"Sample Data\",pad_edge=False, box=box.ASCII)\n\n  for i, row in enumerate(df.values.tolist()):\n    table.add_row(row[0], row[1])\n\n  console.print(table)\n\ntraining_logger = Table(Column(\"Epoch\", justify=\"center\" ), \n                        Column(\"Steps\", justify=\"center\"),\n                        Column(\"Loss\", justify=\"center\"), \n                        title=\"Training Status\",pad_edge=False, box=box.ASCII)\n","metadata":{"id":"wB441x104K-o","execution":{"iopub.status.busy":"2022-11-29T16:18:01.359554Z","iopub.execute_input":"2022-11-29T16:18:01.360822Z","iopub.status.idle":"2022-11-29T16:18:05.924797Z","shell.execute_reply.started":"2022-11-29T16:18:01.360792Z","shell.execute_reply":"2022-11-29T16:18:05.924074Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Setting up the device for GPU usage\nfrom torch import cuda\ndevice = 'cuda' if cuda.is_available() else 'cpu'","metadata":{"id":"tlYaKW9h4ai_","execution":{"iopub.status.busy":"2022-11-29T16:18:05.927344Z","iopub.execute_input":"2022-11-29T16:18:05.927594Z","iopub.status.idle":"2022-11-29T16:18:05.983043Z","shell.execute_reply.started":"2022-11-29T16:18:05.927563Z","shell.execute_reply":"2022-11-29T16:18:05.981978Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class YourDataSetClass(Dataset):\n  \"\"\"\n  Creating a custom dataset for reading the dataset and \n  loading it into the dataloader to pass it to the neural network for finetuning the model\n\n  \"\"\"\n\n  def __init__(self, dataframe, tokenizer, source_len, target_len, toxic_comment, civil_comment):\n    self.tokenizer = tokenizer\n    self.data = dataframe\n    self.source_len = source_len\n    self.summ_len = target_len\n    self.civil_comment = self.data[civil_comment]\n    self.toxic_comment = self.data[toxic_comment]\n\n  def __len__(self):\n    return len(self.civil_comment)\n\n  def __getitem__(self, index):\n    toxic_comment = str(self.toxic_comment[index])\n    civil_comment = str(self.civil_comment[index])\n\n    #cleaning data so as to ensure data is in string type\n    toxic_comment = ' '.join(toxic_comment.split())\n    civil_comment = ' '.join(civil_comment.split())\n\n    source = self.tokenizer.batch_encode_plus([toxic_comment], max_length= self.source_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n    target = self.tokenizer.batch_encode_plus([civil_comment], max_length= self.summ_len, pad_to_max_length=True, truncation=True, padding=\"max_length\", return_tensors='pt')\n\n    source_ids = source['input_ids'].squeeze()\n    source_mask = source['attention_mask'].squeeze()\n    target_ids = target['input_ids'].squeeze()\n    target_mask = target['attention_mask'].squeeze()\n\n    return {\n        'source_ids': source_ids.to(dtype=torch.long), \n        'source_mask': source_mask.to(dtype=torch.long), \n        'target_ids': target_ids.to(dtype=torch.long),\n        'target_ids_y': target_ids.to(dtype=torch.long)\n    }","metadata":{"id":"8vLQPGAn4v17","execution":{"iopub.status.busy":"2022-11-29T16:18:05.984550Z","iopub.execute_input":"2022-11-29T16:18:05.985112Z","iopub.status.idle":"2022-11-29T16:18:05.999014Z","shell.execute_reply.started":"2022-11-29T16:18:05.985076Z","shell.execute_reply":"2022-11-29T16:18:05.998260Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def train(epoch, tokenizer, model, device, loader, optimizer):\n\n  \"\"\"\n  Function to be called for training with the parameters passed from main function\n\n  \"\"\"\n\n  model.train()\n  for _,data in enumerate(loader, 0):\n    y = data['target_ids'].to(device, dtype = torch.long)\n    y_ids = y[:, :-1].contiguous()\n    lm_labels = y[:, 1:].clone().detach()\n    lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n    ids = data['source_ids'].to(device, dtype = torch.long)\n    mask = data['source_mask'].to(device, dtype = torch.long)\n\n    outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n    loss = outputs[0]\n\n    if _%10==0:\n      training_logger.add_row(str(epoch), str(_), str(loss))\n      console.print(training_logger)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","metadata":{"id":"Nkj6wIMt40RK","execution":{"iopub.status.busy":"2022-11-29T16:18:06.000448Z","iopub.execute_input":"2022-11-29T16:18:06.000810Z","iopub.status.idle":"2022-11-29T16:18:06.010327Z","shell.execute_reply.started":"2022-11-29T16:18:06.000772Z","shell.execute_reply":"2022-11-29T16:18:06.009605Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def validate(epoch, tokenizer, model, device, loader):\n\n  \"\"\"\n  Function to evaluate model for predictions\n\n  \"\"\"\n  model.eval()\n  predictions = []\n  actuals = []\n  with torch.no_grad():\n      for _, data in enumerate(loader, 0):\n          y = data['target_ids'].to(device, dtype = torch.long)\n          ids = data['source_ids'].to(device, dtype = torch.long)\n          mask = data['source_mask'].to(device, dtype = torch.long)\n\n          generated_ids = model.generate(\n              input_ids = ids,\n              attention_mask = mask, \n              max_length=150, \n              num_beams=2,\n              repetition_penalty=2.5, \n              length_penalty=1.0, \n              early_stopping=True\n              )\n          preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n          target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n          if _%10==0:\n              console.print(f'Completed {_}')\n\n          predictions.extend(preds)\n          actuals.extend(target)\n  return predictions, actuals","metadata":{"id":"GUBykK-A43DF","execution":{"iopub.status.busy":"2022-11-29T16:18:06.011767Z","iopub.execute_input":"2022-11-29T16:18:06.012074Z","iopub.status.idle":"2022-11-29T16:18:06.021128Z","shell.execute_reply.started":"2022-11-29T16:18:06.012031Z","shell.execute_reply":"2022-11-29T16:18:06.020497Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"V5L4wr3h4612"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def T5Trainer(dataframe, toxic_comment, civil_comment, model_params, output_dir=\"./outputs/\" ):\n  \n  \"\"\"\n  T5 trainer\n\n  \"\"\"\n\n  # Set random seeds and deterministic pytorch for reproducibility\n  torch.manual_seed(model_params[\"SEED\"]) # pytorch random seed\n  np.random.seed(model_params[\"SEED\"]) # numpy random seed\n  torch.backends.cudnn.deterministic = True\n\n  # logging\n  console.log(f\"\"\"[Model]: Loading {model_params[\"MODEL\"]}...\\n\"\"\")\n\n  # tokenzier for encoding the text\n  tokenizer = T5Tokenizer.from_pretrained(model_params[\"MODEL\"])\n\n  # Defining the model. We are using t5-base model and added a Language model layer on top for generation of Summary. \n  # Further this model is sent to device (GPU/TPU) for using the hardware.\n  model = T5ForConditionalGeneration.from_pretrained(model_params[\"MODEL\"])\n  model = model.to(device)\n  \n  # logging\n  console.log(f\"[Data]: Reading data...\\n\")\n\n  # Importing the raw dataset\n  dataframe = dataframe[[toxic_comment,civil_comment]]\n  display_df(dataframe.head(2))\n\n  \n  # Creation of Dataset and Dataloader\n  # Defining the train size. So 80% of the data will be used for training and the rest for validation. \n  train_size = 0.8\n  train_dataset=dataframe.sample(frac=train_size,random_state = model_params[\"SEED\"])\n  val_dataset=dataframe.drop(train_dataset.index).reset_index(drop=True)\n  train_dataset = train_dataset.reset_index(drop=True)\n\n  console.print(f\"FULL Dataset: {dataframe.shape}\")\n  console.print(f\"TRAIN Dataset: {train_dataset.shape}\")\n  console.print(f\"TEST Dataset: {val_dataset.shape}\\n\")\n\n\n  # Creating the Training and Validation dataset for further creation of Dataloader\n  training_set = YourDataSetClass(train_dataset, tokenizer, model_params[\"MAX_toxic_comment_LENGTH\"], model_params[\"MAX_civil_comment_LENGTH\"], toxic_comment, civil_comment)\n  val_set = YourDataSetClass(val_dataset, tokenizer, model_params[\"MAX_toxic_comment_LENGTH\"], model_params[\"MAX_civil_comment_LENGTH\"], toxic_comment, civil_comment)\n\n\n  # Defining the parameters for creation of dataloaders\n  train_params = {\n      'batch_size': model_params[\"TRAIN_BATCH_SIZE\"],\n      'shuffle': True,\n      'num_workers': 0\n      }\n\n\n  val_params = {\n      'batch_size': model_params[\"VALID_BATCH_SIZE\"],\n      'shuffle': False,\n      'num_workers': 0\n      }\n\n\n  # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n  training_loader = DataLoader(training_set, **train_params)\n  val_loader = DataLoader(val_set, **val_params)\n\n\n  # Defining the optimizer that will be used to tune the weights of the network in the training session. \n  optimizer = torch.optim.Adam(params =  model.parameters(), lr=model_params[\"LEARNING_RATE\"])\n\n\n  # Training loop\n  console.log(f'[Initiating Fine Tuning]...\\n')\n\n  for epoch in range(model_params[\"TRAIN_EPOCHS\"]):\n      train(epoch, tokenizer, model, device, training_loader, optimizer)\n      \n  console.log(f\"[Saving Model]...\\n\")\n  #Saving the model after training\n  path = os.path.join(output_dir, \"model_files\")\n  model.save_pretrained(path)\n  tokenizer.save_pretrained(path)\n\n\n  # evaluating test dataset\n  console.log(f\"[Initiating Validation]...\\n\")\n  for epoch in range(model_params[\"VAL_EPOCHS\"]):\n    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)\n    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n    final_df.to_csv(os.path.join(output_dir,'predictions.csv'))\n  \n  console.save_text(os.path.join(output_dir,'logs.txt'))\n  \n  console.log(f\"[Validation Completed.]\\n\")\n  console.print(f\"\"\"[Model] Model saved @ {os.path.join(output_dir, \"model_files\")}\\n\"\"\")\n  console.print(f\"\"\"[Validation] Generation on Validation data saved @ {os.path.join(output_dir,'predictions.csv')}\\n\"\"\")\n  console.print(f\"\"\"[Logs] Logs saved @ {os.path.join(output_dir,'logs.txt')}\\n\"\"\")","metadata":{"id":"Tw4RW_qO4_8T","execution":{"iopub.status.busy":"2022-11-29T16:18:06.022440Z","iopub.execute_input":"2022-11-29T16:18:06.023090Z","iopub.status.idle":"2022-11-29T16:18:06.036990Z","shell.execute_reply.started":"2022-11-29T16:18:06.023037Z","shell.execute_reply":"2022-11-29T16:18:06.036415Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model_params={\n    \"MODEL\":\"t5-base\",             # model_type: t5-base/t5-large\n    \"TRAIN_BATCH_SIZE\":8,          # training batch size\n    \"VALID_BATCH_SIZE\":8,          # validation batch size\n    \"TRAIN_EPOCHS\":3,              # number of training epochs\n    \"VAL_EPOCHS\":1,                # number of validation epochs\n    \"LEARNING_RATE\":1e-4,          # learning rate\n    \"MAX_toxic_comment_LENGTH\":512,  # max length of source text\n    \"MAX_civil_comment_LENGTH\":50,   # max length of target text\n    \"SEED\": 42                     # set seed for reproducibility \n\n}","metadata":{"id":"PxCpQwD8PDIs","jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-11-29T16:18:06.038253Z","iopub.execute_input":"2022-11-29T16:18:06.038537Z","iopub.status.idle":"2022-11-29T16:18:06.047942Z","shell.execute_reply.started":"2022-11-29T16:18:06.038488Z","shell.execute_reply":"2022-11-29T16:18:06.047087Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"T5Trainer(dataframe=df[:500], toxic_comment =\"toxic_comment\", civil_comment=\"civil_comment\", model_params=model_params, output_dir=\"outputs\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":659,"referenced_widgets":["ec5849d8a5434e368153925d3c926271","4e52a776978447cfb9bdd2dd4b55eca8","119499edff2041d9a7800523a433ad7e","e2b569d279ad4a77997edef9b048ad23","3a4fcbff6ae14ebe82ff5f9afa51eea5","f76da56542de46a6825c8efea1ecdce6","97281a8776a64c798113552e532fd901","80c965eb8a40402c8f8a5af8eac653e0","cac07e15804d4e13bb6f9c515e50253a","f32c4f17126a4f8e9ee5c9603eb108f5","a9220a0ea4484ad6977243b1eb33a739","7403bbee5c0841669ebac6cceeae6bd4","c6b4377d2e8a478f82e2b1eefa49716b","88ab93f1ed214b99b96cf1296ffa2d29","3ebe4aeeffed4036943118a47e35c217","39b5a8ce920641718ad234284f70f7d9","879f46c408f14659a50d251aad6f68ee","8d0d63a621504a41bd6e98dc666560c1","1255f4ec9fa6462ea9f11700a76dc4a2","42fc0f7c5baf478396d1d7049859b474","0b895836485d4671a798ad7ef1fd5abd","ba96a54429f94eb5b6becd5e46a619c4","5453f3f9a5af4c91b247567c9d4369b5","892f4760839a4b86a49a30c9bad8cb80","ffbbabfbb324415db8912f4b9c2375f3","fd72af1849d046cf98a26adf3a958882","aed58cac1cf9462fb8dafa4ed79ced37","6e7b3a9953d0480d9235db06aca8528c","0d50c1c93cff48bfb2a792c0fe3b6221","0accde61d1944696a0acaabf87bd3484","e34482676cd74cc7a302729c463803d9","542c536a1b9a437796d24ac4e52d4baf","8a900107689043a9af4244a7d4a15a6d"]},"id":"qijZoYeI55fM","outputId":"95defc86-d3cc-4b3f-8a8d-724ca6b1771e","execution":{"iopub.status.busy":"2022-11-29T16:18:06.049333Z","iopub.execute_input":"2022-11-29T16:18:06.049572Z","iopub.status.idle":"2022-11-29T16:21:46.595781Z","shell.execute_reply.started":"2022-11-29T16:18:06.049542Z","shell.execute_reply":"2022-11-29T16:21:46.594942Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m[16:18:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m: Loading t5-base\u001b[33m...\u001b[0m                                                             \u001b]8;id=504601;file:///tmp/ipykernel_18/3388244917.py\u001b\\\u001b[2m3388244917.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=62256;file:///tmp/ipykernel_18/3388244917.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:18:06] </span><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span>: Loading t5-base<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                             <a href=\"file:///tmp/ipykernel_18/3388244917.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3388244917.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_18/3388244917.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b468845e5e7f4f06b3c61716c0ce7c02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69cc940587484289865280c1371efae5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03902e68848d4b84bfb370beebabf1a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5d208e0839a4443be16d1e9e9656390"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m[16:19:53]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mData\u001b[1m]\u001b[0m: Reading data\u001b[33m...\u001b[0m                                                                 \u001b]8;id=120463;file:///tmp/ipykernel_18/3388244917.py\u001b\\\u001b[2m3388244917.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=511067;file:///tmp/ipykernel_18/3388244917.py#25\u001b\\\u001b[2m25\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:19:53] </span><span style=\"font-weight: bold\">[</span>Data<span style=\"font-weight: bold\">]</span>: Reading data<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                 <a href=\"file:///tmp/ipykernel_18/3388244917.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3388244917.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_18/3388244917.py#25\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">25</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                                                    Sample Data                                                    \u001b[0m\n+-----------------------------------------------------------------------------------------------------------------+\n|\u001b[1m                     toxic_comment                     \u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                     civil_comment                     \u001b[0m|\n|--------------------------------------------------------+--------------------------------------------------------|\n| summarize: . or the loud ass one - thousand ton beast  |  or the loud  one - thousand ton beast roaring towards |\n|        roaring towards you howling its horn .          |                 you howling its horn .                 |\n|summarize: \" mandated \" and \" right fucking now \" would |        \"Mandated' and \"right now\" would be good.       |\n|                       be good .                        |                                                        |\n+-----------------------------------------------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                    Sample Data                                                    </span>\n+-----------------------------------------------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">                     toxic_comment                      </span>|<span style=\"font-weight: bold\">                      civil_comment                     </span>|\n|--------------------------------------------------------+--------------------------------------------------------|\n| summarize: . or the loud ass one - thousand ton beast  |  or the loud  one - thousand ton beast roaring towards |\n|        roaring towards you howling its horn .          |                 you howling its horn .                 |\n|summarize: \" mandated \" and \" right fucking now \" would |        \"Mandated' and \"right now\" would be good.       |\n|                       be good .                        |                                                        |\n+-----------------------------------------------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"FULL Dataset: \u001b[1m(\u001b[0m\u001b[1;36m500\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">FULL Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TRAIN Dataset: \u001b[1m(\u001b[0m\u001b[1;36m400\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TRAIN Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">400</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TEST Dataset: \u001b[1m(\u001b[0m\u001b[1;36m100\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">TEST Dataset: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Fine Tuning\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                             \u001b]8;id=455157;file:///tmp/ipykernel_18/3388244917.py\u001b\\\u001b[2m3388244917.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=95020;file:///tmp/ipykernel_18/3388244917.py#74\u001b\\\u001b[2m74\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[</span>Initiating Fine Tuning<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                             <a href=\"file:///tmp/ipykernel_18/3388244917.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3388244917.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_18/3388244917.py#74\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">74</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |   0   | tensor(1.5463, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |   0   | tensor(1.5463, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |   0   | tensor(1.5463, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |  10   | tensor(1.6752, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |   0   | tensor(1.5463, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |  10   | tensor(1.6752, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |   0   | tensor(1.5463, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |  10   | tensor(1.6752, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |  20   | tensor(0.9819, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |   0   | tensor(1.5463, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |  10   | tensor(1.6752, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |  20   | tensor(0.9819, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |   0   | tensor(1.5463, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |  10   | tensor(1.6752, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |  20   | tensor(0.9819, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |  30   | tensor(1.9589, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |   0   | tensor(1.5463, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |  10   | tensor(1.6752, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |  20   | tensor(0.9819, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |  30   | tensor(1.9589, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[3m                              Training Status                               \u001b[0m\n+--------------------------------------------------------------------------+\n|\u001b[1mEpoch\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1mSteps\u001b[0m\u001b[1m \u001b[0m|\u001b[1m \u001b[0m\u001b[1m                           Loss                           \u001b[0m|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |   0   | tensor(1.5463, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |  10   | tensor(1.6752, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |  20   | tensor(0.9819, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |  30   | tensor(1.9589, device='cuda:0', grad_fn=<NllLossBackward>)|\n|  2   |  40   | tensor(1.3829, device='cuda:0', grad_fn=<NllLossBackward>)|\n+--------------------------------------------------------------------------+\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                              Training Status                               </span>\n+--------------------------------------------------------------------------+\n|<span style=\"font-weight: bold\">Epoch </span>|<span style=\"font-weight: bold\"> Steps </span>|<span style=\"font-weight: bold\">                            Loss                           </span>|\n|------+-------+-----------------------------------------------------------|\n|  0   |   0   | tensor(7.3722, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  10   | tensor(2.6634, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  20   | tensor(2.0730, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  30   | tensor(2.3032, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  0   |  40   | tensor(2.4450, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |   0   | tensor(1.2940, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  10   | tensor(2.2088, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  20   | tensor(2.1865, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  30   | tensor(1.5669, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  1   |  40   | tensor(2.6022, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |   0   | tensor(1.5463, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |  10   | tensor(1.6752, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |  20   | tensor(0.9819, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |  30   | tensor(1.9589, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n|  2   |  40   | tensor(1.3829, device='cuda:0', grad_fn=&lt;NllLossBackward&gt;)|\n+--------------------------------------------------------------------------+\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m[16:21:25]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mSaving Model\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                                       \u001b]8;id=645498;file:///tmp/ipykernel_18/3388244917.py\u001b\\\u001b[2m3388244917.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=512543;file:///tmp/ipykernel_18/3388244917.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:21:25] </span><span style=\"font-weight: bold\">[</span>Saving Model<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                       <a href=\"file:///tmp/ipykernel_18/3388244917.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3388244917.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_18/3388244917.py#79\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">79</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m[16:21:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mInitiating Validation\u001b[1m]\u001b[0m\u001b[33m...\u001b[0m                                                              \u001b]8;id=518536;file:///tmp/ipykernel_18/3388244917.py\u001b\\\u001b[2m3388244917.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=819169;file:///tmp/ipykernel_18/3388244917.py#87\u001b\\\u001b[2m87\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:21:27] </span><span style=\"font-weight: bold\">[</span>Initiating Validation<span style=\"font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                              <a href=\"file:///tmp/ipykernel_18/3388244917.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3388244917.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_18/3388244917.py#87\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">87</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"name":"stderr","text":"2022-11-29 16:21:29.183453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Completed \u001b[1;36m0\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Completed \u001b[1;36m10\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Completed <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[2;36m[16:21:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1m[\u001b[0mValidation Completed.\u001b[1m]\u001b[0m                                                                 \u001b]8;id=520764;file:///tmp/ipykernel_18/3388244917.py\u001b\\\u001b[2m3388244917.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=830608;file:///tmp/ipykernel_18/3388244917.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n\u001b[2;36m           \u001b[0m                                                                                        \u001b[2m                \u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[16:21:46] </span><span style=\"font-weight: bold\">[</span>Validation Completed.<span style=\"font-weight: bold\">]</span>                                                                 <a href=\"file:///tmp/ipykernel_18/3388244917.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3388244917.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_18/3388244917.py#95\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">95</span></a>\n<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                        <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                </span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m[\u001b[0mModel\u001b[1m]\u001b[0m Model saved @ outputs/model_files\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Model<span style=\"font-weight: bold\">]</span> Model saved @ outputs/model_files\n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m[\u001b[0mValidation\u001b[1m]\u001b[0m Generation on Validation data saved @ outputs/predictions.csv\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Validation<span style=\"font-weight: bold\">]</span> Generation on Validation data saved @ outputs/predictions.csv\n\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m[\u001b[0mLogs\u001b[1m]\u001b[0m Logs saved @ outputs/logs.txt\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>Logs<span style=\"font-weight: bold\">]</span> Logs saved @ outputs/logs.txt\n\n</pre>\n"},"metadata":{}}]}]}