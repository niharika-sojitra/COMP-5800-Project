{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn2myvHdgF0QFZ4tSgHOos",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niharika-sojitra/COMP-5800-Project/blob/main/CAE_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/LeoLaugier/conditional-auto-encoder-text-to-text-transfer-transformer.git\n",
        "\n",
        "%cd conditional-auto-encoder-text-to-text-transfer-transformer \n",
        "\n",
        "!pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-MX_dH3kGhh",
        "outputId": "85f1f6a5-1f47-49c5-f8ab-233562088222"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'conditional-auto-encoder-text-to-text-transfer-transformer'...\n",
            "remote: Enumerating objects: 661, done.\u001b[K\n",
            "remote: Counting objects: 100% (205/205), done.\u001b[K\n",
            "remote: Compressing objects: 100% (77/77), done.\u001b[K\n",
            "remote: Total 661 (delta 125), reused 204 (delta 124), pack-reused 456\u001b[K\n",
            "Receiving objects: 100% (661/661), 189.09 KiB | 2.86 MiB/s, done.\n",
            "Resolving deltas: 100% (400/400), done.\n",
            "/content/conditional-auto-encoder-text-to-text-transfer-transformer/conditional-auto-encoder-text-to-text-transfer-transformer\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /content/conditional-auto-encoder-text-to-text-transfer-transformer/conditional-auto-encoder-text-to-text-transfer-transformer\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.7/dist-packages (from caet5==0.0.0) (1.12.11)\n",
            "Requirement already satisfied: google-cloud_storage in /usr/local/lib/python3.7/dist-packages (from caet5==0.0.0) (2.5.0)\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (from caet5==0.0.0) (0.12.0)\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.7/dist-packages (from caet5==0.0.0) (0.13.1)\n",
            "Requirement already satisfied: transformers==2.8.0 in /usr/local/lib/python3.7/dist-packages (from caet5==0.0.0) (2.8.0)\n",
            "Requirement already satisfied: t5==0.5.0 in /usr/local/lib/python3.7/dist-packages (from caet5==0.0.0) (0.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (1.18.5)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (4.7.0.dev202211280045)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (0.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (0.1.97)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (3.7)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (0.5.0)\n",
            "Requirement already satisfied: mesh-tensorflow[transformer]>=0.1.13 in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (0.1.21)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (2.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (1.0.2)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (2.11.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (1.12.1+cu113)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (1.4.1)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (2.3.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.14 in /usr/local/lib/python3.7/dist-packages (from t5==0.5.0->caet5==0.0.0) (1.15.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0->caet5==0.0.0) (0.0.53)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0->caet5==0.0.0) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0->caet5==0.0.0) (1.26.17)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0->caet5==0.0.0) (4.64.1)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0->caet5==0.0.0) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0->caet5==0.0.0) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.8.0->caet5==0.0.0) (2022.6.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (4.6.0)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->t5==0.5.0->caet5==0.0.0) (2022.6)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0->caet5==0.0.0) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0->caet5==0.0.0) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.17 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers==2.8.0->caet5==0.0.0) (1.29.17)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.17->boto3->transformers==2.8.0->caet5==0.0.0) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.17->boto3->transformers==2.8.0->caet5==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->caet5==0.0.0) (0.17.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->caet5==0.0.0) (2.8.2)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->caet5==0.0.0) (0.0.4)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->caet5==0.0.0) (3.0.1)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client->caet5==0.0.0) (2.14.1)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client->caet5==0.0.0) (3.19.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client->caet5==0.0.0) (1.57.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client->caet5==0.0.0) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client->caet5==0.0.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client->caet5==0.0.0) (0.2.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client->caet5==0.0.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0->caet5==0.0.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0->caet5==0.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.8.0->caet5==0.0.0) (3.0.4)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud_storage->caet5==0.0.0) (2.4.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud_storage->caet5==0.0.0) (2.3.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media>=2.3.2->google-cloud_storage->caet5==0.0.0) (1.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->t5==0.5.0->caet5==0.0.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->t5==0.5.0->caet5==0.0.0) (1.2.0)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5==0.5.0->caet5==0.0.0) (2.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5==0.5.0->caet5==0.0.0) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5==0.5.0->caet5==0.0.0) (4.9.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5==0.5.0->caet5==0.0.0) (0.8.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->t5==0.5.0->caet5==0.0.0) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (1.11.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (0.10.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (5.10.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (2.1.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (0.3.6)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (4.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.7/dist-packages (from etils[epath]->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5==0.5.0->caet5==0.0.0) (3.10.0)\n",
            "Requirement already satisfied: tensorflow<2.4,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-text->t5==0.5.0->caet5==0.0.0) (2.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (1.1.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (1.50.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (0.38.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (2.11.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (1.6.3)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (3.3.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (2.10.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (2.3.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (3.4.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (4.13.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow<2.4,>=2.3.0->tensorflow-text->t5==0.5.0->caet5==0.0.0) (3.2.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5==0.5.0->caet5==0.0.0) (0.1.7)\n",
            "Building wheels for collected packages: caet5\n",
            "  Building wheel for caet5 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for caet5: filename=caet5-0.0.0-py3-none-any.whl size=56126 sha256=5a5dd67485657a9b440fc205a45eaf7967e328f8295f2d405644207632664974\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/4c/b4/47bab98b74e556e1cc8003729643817fe3e1b2890f3e1f4c8a\n",
            "Successfully built caet5\n",
            "Installing collected packages: caet5\n",
            "  Attempting uninstall: caet5\n",
            "    Found existing installation: caet5 0.0.0\n",
            "    Uninstalling caet5-0.0.0:\n",
            "      Successfully uninstalled caet5-0.0.0\n",
            "Successfully installed caet5-0.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -U tensorflow-gcs-config==2.1.3.  ==2.9.1\n",
        "\n",
        "!pip install -U tensorflow-gcs-config==2.3\n",
        "\n",
        "!pip install tensorflow==2.3 t5 tensorflow-text==2.3\n",
        "#!pip install tensorflow t5 tensorflow-text"
      ],
      "metadata": {
        "id": "eFU3mGh_liPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce007192-5f68-413e-c714-79c7963f45bf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-gcs-config==2.3 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.3 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: t5 in /usr/local/lib/python3.7/dist-packages (0.5.0)\n",
            "Requirement already satisfied: tensorflow-text==2.3 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (1.14.1)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (1.18.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (1.50.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (2.3.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (1.3.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (1.1.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (3.19.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (2.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (1.6.3)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (1.4.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (2.11.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.3) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3) (3.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3) (4.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3) (3.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from t5) (3.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from t5) (0.1.97)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from t5) (0.5.0)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.7/dist-packages (from t5) (2.11.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from t5) (1.0.2)\n",
            "Requirement already satisfied: mesh-tensorflow[transformer]>=0.1.13 in /usr/local/lib/python3.7/dist-packages (from t5) (0.1.21)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from t5) (2.3.1)\n",
            "Requirement already satisfied: tfds-nightly in /usr/local/lib/python3.7/dist-packages (from t5) (4.7.0.dev202211280045)\n",
            "Requirement already satisfied: transformers>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from t5) (2.8.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from t5) (1.12.1+cu113)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from t5) (1.3.5)\n",
            "Requirement already satisfied: rouge-score in /usr/local/lib/python3.7/dist-packages (from t5) (0.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from mesh-tensorflow[transformer]>=0.1.13->t5) (4.6.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5) (1.26.17)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5) (4.64.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5) (0.0.53)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5) (2022.6.2)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.7/dist-packages (from transformers>=2.7.0->t5) (0.5.2)\n",
            "Requirement already satisfied: pytz>=2015.7 in /usr/local/lib/python3.7/dist-packages (from babel->t5) (2022.6)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers>=2.7.0->t5) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers>=2.7.0->t5) (0.6.0)\n",
            "Requirement already satisfied: botocore<1.30.0,>=1.29.17 in /usr/local/lib/python3.7/dist-packages (from boto3->transformers>=2.7.0->t5) (1.29.17)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.30.0,>=1.29.17->boto3->transformers>=2.7.0->t5) (2.8.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->t5) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->t5) (7.1.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5) (2.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5) (4.9.1)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->t5) (0.8.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->t5) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (1.11.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (5.10.0)\n",
            "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (0.9.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (0.10.2)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (2.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (0.3.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-metadata->tensorflow-datasets->mesh-tensorflow[transformer]>=0.1.13->t5) (1.57.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tfds-nightly->t5) (0.1.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n"
      ],
      "metadata": {
        "id": "VeqfqYwRYO5D"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try: # detect TPUs\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n",
        "    strategy = tf.distribute.TPUStrategy(tpu)\n",
        "except ValueError: # detect GPUs\n",
        "    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
        "\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_chhk1DkZOI_",
        "outputId": "af40621d-36b2-4ef2-c3c7-a8f9163b961b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.120.21.42:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of accelerators:  8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "else:\n",
        "  TF_MASTER=''\n",
        "\n",
        "tpu_address = TF_MASTER"
      ],
      "metadata": {
        "id": "_07Or3fLb43e"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ],
      "metadata": {
        "id": "BJ9hgYXyYHpl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c1c83a-3132-4f04-b812-6df525069584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.120.21.42:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gcloud auth application-default login\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()"
      ],
      "metadata": {
        "id": "E37wpNu2tia5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "\n",
        "def authenticate_implicit_with_adc(project_id=\"your-google-cloud-project-id\"):\n",
        "    \"\"\"\n",
        "    When interacting with Google Cloud Client libraries, the library can auto-detect the\n",
        "    credentials to use.\n",
        "\n",
        "    // TODO(Developer):\n",
        "    //  1. Before running this sample,\n",
        "    //  set up ADC as described in https://cloud.google.com/docs/authentication/external/set-up-adc\n",
        "    //  2. Replace the project variable.\n",
        "    //  3. Make sure that the user account or service account that you are using\n",
        "    //  has the required permissions. For this sample, you must have \"storage.buckets.list\".\n",
        "    Args:\n",
        "        project_id: The project id of your Google Cloud project.\n",
        "    \"\"\"\n",
        "\n",
        "    # This snippet demonstrates how to list buckets.\n",
        "    # *NOTE*: Replace the client created below with the client required for your application.\n",
        "    # Note that the credentials are not specified when constructing the client.\n",
        "    # Hence, the client library will look for credentials using ADC.\n",
        "    storage_client = storage.Client(project=project_id)\n",
        "    buckets = storage_client.list_buckets()\n",
        "    print(\"Buckets:\")\n",
        "    for bucket in buckets:\n",
        "        print(bucket.name)\n",
        "    print(\"Listed all storage buckets.\")\n",
        "\n",
        "authenticate_implicit_with_adc(project_id=\"my-project-5800-369416\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avUEDP-l6uiV",
        "outputId": "1bc10afc-7471-426e-f372-e32dd5676811"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buckets:\n",
            "buck_10\n",
            "Listed all storage buckets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Setting up GCS access...\")\n",
        "import tensorflow as tf\n",
        "import tensorflow_gcs_config\n",
        "from google.colab import auth\n",
        "\n",
        "# Set credentials for GCS reading/writing from Colab and TPU.\n",
        "TPU_TOPOLOGY = \"2x2\"\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  TPU_ADDRESS = tpu.get_master()\n",
        "  print('Running on TPU:', TPU_ADDRESS)\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "auth.authenticate_user()\n",
        "tf.config.experimental_connect_to_host(TPU_ADDRESS)\n",
        "tensorflow_gcs_config.configure_gcs_from_colab_auth()\n",
        "\n",
        "%env TPU_ADDRESS=$TPU_ADDRESS"
      ],
      "metadata": {
        "id": "Qyh2lXFxkHcF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "eb46722e-6345-4efb-f21e-ded40fb919ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up GCS access...\n",
            "Running on TPU: grpc://10.120.21.42:8470\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-67c6eb672018>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_connect_to_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTPU_ADDRESS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtensorflow_gcs_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure_gcs_from_colab_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'env'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TPU_ADDRESS=$TPU_ADDRESS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_gcs_config/__init__.py\u001b[0m in \u001b[0;36mconfigure_gcs_from_colab_auth\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    130\u001b[0m   adc_filename = os.environ.get(\n\u001b[1;32m    131\u001b[0m       \"GOOGLE_APPLICATION_CREDENTIALS\", \"/content/adc.json\")\n\u001b[0;32m--> 132\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madc_filename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconfigure_gcs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/adc.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = \"gs://buck_10\"  # @param { type: \"string\" }\n",
        "%env BASE_DIR = $base_dir\n",
        "models_dir_name = \"my-project-5800\" # @param { type: \"string\" }\n",
        "%env MODELS_DIR_NAME = $models_dir_name\n",
        "MODELS_DIR = os.path.join(base_dir, models_dir_name)\n",
        "model_size = \"large\"\n",
        "%env MODEL_SIZE = $model_size\n",
        "model_dir_counter = 1 # @param { type: \"integer\" }\n",
        "%env MODEL_DIR_COUNTER = $model_dir_counter\n",
        "bucket = \"buck_10\" # @param { type: \"string\" }\n",
        "%env BUCKET = $bucket\n",
        "data_dir_name = \"dat_dir\" # @param { type: \"string\" }\n",
        "%env DATA_DIR_NAME = $data_dir_name "
      ],
      "metadata": {
        "id": "xenWcRHxkPUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a9d2ee-554b-4914-c1f9-1cc51fe9cd48"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: BASE_DIR=gs://buck_10\n",
            "env: MODELS_DIR_NAME=my-project-5800\n",
            "env: MODEL_SIZE=large\n",
            "env: MODEL_DIR_COUNTER=1\n",
            "env: BUCKET=buck_10\n",
            "env: DATA_DIR_NAME=dat_dir\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_steps = 100000 # @param { type: \"integer\" }\n",
        "%env TRAINING_STEPS = $training_steps\n",
        "task = \"yelp\" # @param { type: \"string\" }\n",
        "mixture = \"mixture_%s\" %task \n",
        "%env MIXTURE = $mixture\n",
        "sequence_length_gin = os.path.join(\"sequence_lengths\", \"%s.gin\" % task)\n",
        "%env SEQUENCE_LENGTH_GIN = $sequence_length_gin\n",
        "control_codes_gin = os.path.join(\"control_codes\", \"%s.gin\" % task)\n",
        "%env CONTROL_CODES_GIN = $control_codes_gin"
      ],
      "metadata": {
        "id": "VIebMTINq700",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "888d8f78-31ad-4b4a-f08d-92a303a64963"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: TRAINING_STEPS=100000\n",
            "env: MIXTURE=mixture_yelp\n",
            "env: SEQUENCE_LENGTH_GIN=sequence_lengths/yelp.gin\n",
            "env: CONTROL_CODES_GIN=control_codes/yelp.gin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!caet5 --base_dir=\"${BASE_DIR}\" \\\n",
        "       --model_dir_name=\"${MODELS_DIR_NAME}\" \\\n",
        "       --model_size=\"${MODEL_SIZE}\" \\\n",
        "       --model_dir_counter=\"${MODEL_DIR_COUNTER}\" \\\n",
        "       --tpu=\"${TPU_ADDRESS}\" \\\n",
        "       --module_import=caet5.data.tasks \\\n",
        "       --use_model_api=True \\\n",
        "       --mode=\"finetune\" \\\n",
        "       --bucket=\"${BUCKET}\" \\\n",
        "       --data_raw_dir_name=\"yelp_processed\" \\\n",
        "       --train_steps=\"${TRAINING_STEPS}\" \\\n",
        "       --mixture_or_task=\"${MIXTURE}\" \\\n",
        "       --base_pretrained_model_dir=\"gs://t5-data/pretrained_models/\" \\\n",
        "       --gin_file=\"dataset.gin\" \\\n",
        "       --gin_file=\"objectives/denoise.gin\" \\\n",
        "       --gin_file=\"models/cae_bi.gin\" \\\n",
        "       --gin_file=\"train.gin\" \\\n",
        "       --gin_file=\"${SEQUENCE_LENGTH_GIN}\" \\\n",
        "       --gin_file=\"${CONTROL_CODES_GIN}\" \\\n",
        "       --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '2x2'\""
      ],
      "metadata": {
        "id": "y5Wza5aFq91t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5ea729e-01b0-498a-addc-c481f7b98dbb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-29 01:43:01.719523: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-29 01:43:01.719594: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/utils/tf_utils.py:200: FutureWarning: Conversion of the second argument of issubdtype from `object` to `np.generic` is deprecated. In future, it will be treated as `np.object_ == np.dtype(object).type`.\n",
            "  return np.issubdtype(value, super_type)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "I1129 01:43:09.674908 139731389220736 file_utils.py:41] PyTorch version 1.12.1+cu113 available.\n",
            "I1129 01:43:09.675199 139731389220736 file_utils.py:57] TensorFlow version 2.3.0 available.\n",
            "I1129 01:43:10.091515 139731389220736 resolver.py:106] Using /tmp/tfhub_modules to cache modules.\n",
            "W1129 01:43:12.608596 139731389220736 __init__.py:48] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "W1129 01:43:12.688911 139731389220736 _default.py:642] No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "INFO:tensorflow:Generating TSV for the train split.\n",
            "I1129 01:43:13.183097 139731389220736 tasks.py:118] Generating TSV for the train split.\n",
            "INFO:tensorflow:TSV for the train split generated.\n",
            "I1129 01:43:13.323357 139731389220736 tasks.py:128] TSV for the train split generated.\n",
            "INFO:tensorflow:Generating TSV for the validation split.\n",
            "I1129 01:43:13.323682 139731389220736 tasks.py:118] Generating TSV for the validation split.\n",
            "INFO:tensorflow:TSV for the validation split generated.\n",
            "I1129 01:43:13.400269 139731389220736 tasks.py:128] TSV for the validation split generated.\n",
            "INFO:tensorflow:Generating TSV for the test split.\n",
            "I1129 01:43:13.400562 139731389220736 tasks.py:118] Generating TSV for the test split.\n",
            "INFO:tensorflow:TSV for the test split generated.\n",
            "I1129 01:43:13.492292 139731389220736 tasks.py:128] TSV for the test split generated.\n",
            "INFO:tensorflow:Fine-tuned attribute classifier not found on local machine.\n",
            "I1129 01:43:13.493384 139731389220736 metrics_utils.py:56] Fine-tuned attribute classifier not found on local machine.\n",
            "INFO:tensorflow:Fine-tuned fine-tuned attribute classifier binary not found on bucket, please store one either on local (in [metric_name]_binaries/) or on the GCS bucket (in [metric_name]_binaries/).\n",
            "I1129 01:43:13.642684 139731389220736 metrics_utils.py:68] Fine-tuned fine-tuned attribute classifier binary not found on bucket, please store one either on local (in [metric_name]_binaries/) or on the GCS bucket (in [metric_name]_binaries/).\n",
            "I1129 01:43:13.828171 139731389220736 configuration_utils.py:283] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I1129 01:43:13.828887 139731389220736 configuration_utils.py:319] Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I1129 01:43:14.011501 139731389220736 tokenization_utils.py:504] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "I1129 01:43:14.276948 139731389220736 configuration_utils.py:283] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "I1129 01:43:14.277661 139731389220736 configuration_utils.py:319] Model config BertConfig {\n",
            "  \"_num_labels\": 1,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bad_words_ids\": null,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "I1129 01:43:14.443083 139731389220736 modeling_utils.py:507] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "I1129 01:43:18.827659 139731389220736 modeling_utils.py:601] Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
            "I1129 01:43:18.827914 139731389220736 modeling_utils.py:607] Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/evaluation/metrics_utils.py\", line 88, in load_finetuned_transformer\n",
            "    pretrained_model.load_state_dict(torch.load(finetuned_model_local_path, map_location=map_location))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 699, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'acc_binaries/bert_acc_yelp.pt'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/caet5\", line 8, in <module>\n",
            "    sys.exit(console_entry_point())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/main.py\", line 312, in console_entry_point\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/main.py\", line 128, in main\n",
            "    importlib.import_module(module)\n",
            "  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/data/tasks.py\", line 187, in <module>\n",
            "    map_location=torch.device('cpu')))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/evaluation/metrics_utils.py\", line 71, in setup_parametric_evaluator\n",
            "    **load_fn_kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/evaluation/metrics_utils.py\", line 93, in load_finetuned_transformer\n",
            "    raise RuntimeError('Error(s) in loading state_dict for %s.' % evaluator_name)\n",
            "RuntimeError: Error(s) in loading state_dict for Fine-tuned attribute classifier.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!caet5 --base_dir=\"${BASE_DIR}\" \\\n",
        "       --model_dir_name=\"${MODELS_DIR_NAME}\" \\\n",
        "       --model_size=\"${MODEL_SIZE}\" \\\n",
        "       --model_dir_counter=\"${MODEL_DIR_COUNTER}\" \\\n",
        "       --tpu=\"${TPU_ADDRESS}\" \\\n",
        "       --module_import=caet5.data.tasks \\\n",
        "       --use_model_api=True \\\n",
        "       --mode=\"eval\" \\\n",
        "       --bucket=\"${BUCKET}\" \\\n",
        "       --mixture_or_task=\"${MIXTURE}\" \\\n",
        "       --base_pretrained_model_dir=\"gs://t5-data/pretrained_models/\" \\\n",
        "       --checkpoint_mode=\"latest\" \\\n",
        "       --gin_file=\"dataset.gin\" \\\n",
        "       --gin_file=\"models/cae_bi.gin\" \\\n",
        "       --gin_file=\"${SEQUENCE_LENGTH_GIN}\" \\\n",
        "       --gin_file=\"${CONTROL_CODES_GIN}\" \\\n",
        "       --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '2x2'\""
      ],
      "metadata": {
        "id": "u2FkUrm1rCRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36ee404f-cc6e-4454-ef5b-144d044c6a2f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-29 01:43:20.766547: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-29 01:43:20.766604: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/utils/tf_utils.py:200: FutureWarning: Conversion of the second argument of issubdtype from `object` to `np.generic` is deprecated. In future, it will be treated as `np.object_ == np.dtype(object).type`.\n",
            "  return np.issubdtype(value, super_type)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "I1129 01:43:24.566224 140279690274688 file_utils.py:41] PyTorch version 1.12.1+cu113 available.\n",
            "I1129 01:43:24.566413 140279690274688 file_utils.py:57] TensorFlow version 2.3.0 available.\n",
            "I1129 01:43:24.723980 140279690274688 resolver.py:106] Using /tmp/tfhub_modules to cache modules.\n",
            "W1129 01:43:25.846925 140279690274688 __init__.py:48] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "W1129 01:43:25.875914 140279690274688 _default.py:642] No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "INFO:tensorflow:Generating TSV for the train split.\n",
            "I1129 01:43:26.189052 140279690274688 tasks.py:118] Generating TSV for the train split.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/caet5\", line 8, in <module>\n",
            "    sys.exit(console_entry_point())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/main.py\", line 312, in console_entry_point\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/main.py\", line 128, in main\n",
            "    importlib.import_module(module)\n",
            "  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/data/tasks.py\", line 121, in <module>\n",
            "    dataset_raw_dir = os.path.join(FLAGS.base_dir, FLAGS.data_raw_dir_name)\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 94, in join\n",
            "    genericpath._check_arg_types('join', a, *p)\n",
            "  File \"/usr/lib/python3.7/genericpath.py\", line 153, in _check_arg_types\n",
            "    (funcname, s.__class__.__name__)) from None\n",
            "TypeError: join() argument must be str or bytes, not 'NoneType'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import time \n",
        "\n",
        "comment_attribute_pairs = [\n",
        "\n",
        "            {\"text\": \"these donuts have the perfect texture and taste .\",\n",
        "             \"Destination attribute\": \"negative\"},\n",
        "            {\"text\": \"these donuts have the perfect texture and taste .\",\n",
        "             \"Destination attribute\": \"positive\"},\n",
        "\n",
        "            {\"text\": \"good food for the price .\",\n",
        "             \"Destination attribute\": \"negative\"},\n",
        "            {\"text\": \"good food for the price .\",\n",
        "             \"Destination attribute\": \"positive\"},\n",
        "\n",
        "            {\"text\": \"a little dirty on the inside , but wonderful people that work there !\",\n",
        "                \"Destination attribute\": \"negative\"},\n",
        "            {\"text\": \"a little dirty on the inside , but wonderful people that work there !\",\n",
        "                \"Destination attribute\": \"positive\"},\n",
        "\n",
        "            {\"text\": \"i always order it when i go there and it is always awesome .\",\n",
        "             \"Destination attribute\": \"negative\"},\n",
        "            {\"text\": \"i always order it when i go there and it is always awesome .\",\n",
        "             \"Destination attribute\": \"positive\"},\n",
        "\n",
        "            {\"text\": \"the rest of the food there is good also and not very expensive .\",\n",
        "             \"Destination attribute\": \"negative\"},\n",
        "            {\"text\": \"the rest of the food there is good also and not very expensive .\",\n",
        "             \"Destination attribute\": \"positive\"},\n",
        "\n",
        "            {\"text\": \"great food , low prices , and huge quantity !\",\n",
        "             \"Destination attribute\": \"negative\"},\n",
        "            {\"text\": \"great food , low prices , and huge quantity !\",\n",
        "             \"Destination attribute\": \"positive\"},\n",
        "\n",
        "            {\"text\": \"so excited to have a chinese place near my office !\",\n",
        "                \"Destination attribute\": \"negative\"},\n",
        "            {\"text\": \"this is my go to spot for chinese food .\",\n",
        "                \"Destination attribute\": \"positive\"},\n",
        "\n",
        "            {\"text\": \"i guess i need to spell that out more clearly next time .\",\n",
        "             \"Destination attribute\": \"positive\"},\n",
        "            {\"text\": \"i guess i need to spell that out more clearly next time .\",\n",
        "             \"Destination attribute\": \"negative\"},\n",
        "\n",
        "            {\"text\": \"the service the last time i went was just terrible .\",\n",
        "             \"Destination attribute\": \"positive\"},\n",
        "            {\"text\": \"the service the last time i went was just terrible .\",\n",
        "             \"Destination attribute\": \"negative\"},\n",
        "\n",
        "            {\"text\": \"it has n't been for quite a few years .\",\n",
        "                \"Destination attribute\": \"positive\"},\n",
        "            {\"text\": \"it has n't been for quite a few years .\",\n",
        "                \"Destination attribute\": \"negative\"},\n",
        "\n",
        "            {\"text\": \"the food here is n't very good .\",\n",
        "                \"Destination attribute\": \"positive\"},\n",
        "            {\"text\": \"the food here is n't very good .\",\n",
        "                \"Destination attribute\": \"negative\"},\n",
        "\n",
        "            {\"text\": \"i am sad to see how much this place has gone downhill .\",\n",
        "                \"Destination attribute\": \"positive\"},\n",
        "            {\"text\": \"i am sad to see how much this place has gone downhill .\",\n",
        "                \"Destination attribute\": \"negative\"},\n",
        "\n",
        "            {\"text\": \"never again will i go back to this restaurant .\",\n",
        "                \"Destination attribute\": \"positive\"},\n",
        "            {\"text\": \"never again will i go back to this restaurant .\",\n",
        "                \"Destination attribute\": \"negative\"},\n",
        "\n",
        "            {\"text\": \"i would n't go here for a meal ever again .\",\n",
        "                \"Destination attribute\": \"positive\"},\n",
        "            {\"text\": \"i would n't go here for a meal ever again .\",\n",
        "                \"Destination attribute\": \"negative\"},\n",
        "\n",
        "            {\"text\": \"but nothing show stopping .\",\n",
        "                \"Destination attribute\": \"positive\"},\n",
        "            {\"text\": \"but nothing show stopping .\",\n",
        "                \"Destination attribute\": \"negative\"},\n",
        "\n",
        "            {\"text\": \"very rude , will not come back .\",\n",
        "                \"Destination attribute\": \"positive\"},\n",
        "            {\"text\": \"very rude , will not come back .\",\n",
        "                \"Destination attribute\": \"negative\"},\n",
        "        ]\n",
        "\n",
        "attribute_ids = {\"negative\": \"0\", \"positive\": \"1\"}\n",
        "\n",
        "comments = []\n",
        "for p in comment_attribute_pairs:\n",
        "    comments.append(p[\"text\"] + \"|dst_attribute:\" + attribute_ids[p[\"Destination attribute\"]])\n",
        "\n",
        "now = time.time()\n",
        "# Write out the input text to text files.\n",
        "\n",
        "model_dir = os.path.join(\"%s_%s\" % (MODELS_DIR, str(model_dir_counter)), model_size)\n",
        "predict_inputs_path = os.path.join(model_dir, \"predict_inputs_%d.txt\" % now)\n",
        "predict_outputs_path = os.path.join(model_dir, \"predict_outputs_%d.txt\" % now)\n",
        "# Manually apply preprocessing\n",
        "with tf.io.gfile.GFile(predict_inputs_path, \"w\") as f:\n",
        "    for c in comments:\n",
        "        c = re.sub(r'\\n', r\"\\\\n\", c, flags=re.S)\n",
        "        f.write(\"%s\\n\" % c.lower())\n",
        "\n",
        "predict_batch_size = len(comments)\n",
        "%env PREDICT_BATCH_SIZE = $predict_batch_size\n",
        "%env PREDICT_INPUTS_PATH = $predict_inputs_path\n",
        "%env PREDICT_OUTPUTS_PATH = $predict_outputs_path"
      ],
      "metadata": {
        "id": "8eXpl3QRrVzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cf0fb15-fa9b-46a9-ba0d-3f1234aac4d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PREDICT_BATCH_SIZE=32\n",
            "env: PREDICT_INPUTS_PATH=gs://buck_10/my-project-5800_1/large/predict_inputs_1669686496.txt\n",
            "env: PREDICT_OUTPUTS_PATH=gs://buck_10/my-project-5800_1/large/predict_outputs_1669686496.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!caet5 --base_dir=\"${BASE_DIR}\" \\\n",
        "       --model_dir_name=\"${MODELS_DIR_NAME}\" \\\n",
        "       --model_size=\"${MODEL_SIZE}\" \\\n",
        "       --model_dir_counter=\"${MODEL_DIR_COUNTER}\" \\\n",
        "       --tpu=\"${TPU_ADDRESS}\" \\\n",
        "       --module_import=caet5.data.tasks \\\n",
        "       --use_model_api=True \\\n",
        "       --mode=\"predict\" \\\n",
        "       --bucket=\"${BUCKET}\" \\\n",
        "       --mixture_or_task=\"${MIXTURE}\" \\\n",
        "       --base_pretrained_model_dir=\"gs://t5-data/pretrained_models/\" \\\n",
        "       --checkpoint_mode=\"latest\" \\\n",
        "       --input_file=\"${PREDICT_INPUTS_PATH}\" \\\n",
        "       --output_file=\"${PREDICT_OUTPUTS_PATH}\" \\\n",
        "       --predict_batch_size=\"${PREDICT_BATCH_SIZE}\" \\\n",
        "       --gin_file=\"dataset.gin\" \\\n",
        "       --gin_file=\"models/cae_bi.gin\" \\\n",
        "       --gin_file=\"infer.gin\" \\\n",
        "       --gin_file=\"${SEQUENCE_LENGTH_GIN}\" \\\n",
        "       --gin_file=\"${CONTROL_CODES_GIN}\" \\\n",
        "       --gin_param=\"utils.tpu_mesh_shape.tpu_topology = '2x2'\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3WGNMC59L1s",
        "outputId": "9a465011-7255-4a14-adc4-466645a6ed86"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-29 01:48:22.857542: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2022-11-29 01:48:22.857600: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/utils/tf_utils.py:200: FutureWarning: Conversion of the second argument of issubdtype from `object` to `np.generic` is deprecated. In future, it will be treated as `np.object_ == np.dtype(object).type`.\n",
            "  return np.issubdtype(value, super_type)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n",
            "I1129 01:48:26.499638 140708258637696 file_utils.py:41] PyTorch version 1.12.1+cu113 available.\n",
            "I1129 01:48:26.499832 140708258637696 file_utils.py:57] TensorFlow version 2.3.0 available.\n",
            "I1129 01:48:26.665390 140708258637696 resolver.py:106] Using /tmp/tfhub_modules to cache modules.\n",
            "W1129 01:48:27.772691 140708258637696 __init__.py:48] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 44, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    \"file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\"\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "W1129 01:48:27.800661 140708258637696 _default.py:642] No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "INFO:tensorflow:Generating TSV for the train split.\n",
            "I1129 01:48:28.150732 140708258637696 tasks.py:118] Generating TSV for the train split.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/caet5\", line 8, in <module>\n",
            "    sys.exit(console_entry_point())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/main.py\", line 312, in console_entry_point\n",
            "    app.run(main)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/main.py\", line 128, in main\n",
            "    importlib.import_module(module)\n",
            "  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/caet5/data/tasks.py\", line 121, in <module>\n",
            "    dataset_raw_dir = os.path.join(FLAGS.base_dir, FLAGS.data_raw_dir_name)\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 94, in join\n",
            "    genericpath._check_arg_types('join', a, *p)\n",
            "  File \"/usr/lib/python3.7/genericpath.py\", line 153, in _check_arg_types\n",
            "    (funcname, s.__class__.__name__)) from None\n",
            "TypeError: join() argument must be str or bytes, not 'NoneType'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The output filename will have the checkpoint appended so we glob to get\n",
        "# the latest.\n",
        "prediction_files = sorted(tf.io.gfile.glob(predict_outputs_path + \"*\"))\n",
        "print(\"\\nPredictions using checkpoint %s:\\n\" % prediction_files[-1].split(\"-\")[-1])\n",
        "with tf.io.gfile.GFile(prediction_files[-1]) as f:\n",
        "    for c, g in zip(comments, f):\n",
        "        if c:\n",
        "            print(\"Initial text: \" + c.split(\"|dst_style:\")[0])\n",
        "            print(\"Generated text: \" + g)\n",
        "            print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "yheCkMc69QzU",
        "outputId": "5224f2a9-99f2-4f1b-ca6f-b6adf56d5e85"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-99a1b57a965c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# the latest.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprediction_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_outputs_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nPredictions using checkpoint %s:\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mprediction_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    }
  ]
}